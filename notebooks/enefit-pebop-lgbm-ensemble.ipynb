{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19626126",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-06T07:29:18.302678Z",
     "iopub.status.busy": "2024-01-06T07:29:18.302041Z",
     "iopub.status.idle": "2024-01-06T07:29:22.426130Z",
     "shell.execute_reply": "2024-01-06T07:29:22.424886Z"
    },
    "papermill": {
     "duration": 4.136992,
     "end_time": "2024-01-06T07:29:22.429567",
     "exception": false,
     "start_time": "2024-01-06T07:29:18.292575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78f56d",
   "metadata": {
    "papermill": {
     "duration": 0.006713,
     "end_time": "2024-01-06T07:29:22.443859",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.437146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283d564",
   "metadata": {
    "papermill": {
     "duration": 0.006755,
     "end_time": "2024-01-06T07:29:22.457639",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.450884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### DataStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fdfca02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:29:22.474431Z",
     "iopub.status.busy": "2024-01-06T07:29:22.473796Z",
     "iopub.status.idle": "2024-01-06T07:29:22.500886Z",
     "shell.execute_reply": "2024-01-06T07:29:22.499764Z"
    },
    "papermill": {
     "duration": 0.039353,
     "end_time": "2024-01-06T07:29:22.504262",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.464909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataStorage:\n",
    "    root = \"../data/\"\n",
    "\n",
    "    data_cols = [\"target\",\"county\",\"is_business\",\"product_type\",\"is_consumption\",\"datetime\",\"row_id\",]\n",
    "    client_cols = [\"product_type\",\"county\",\"eic_count\",\"installed_capacity\",\"is_business\",\"date\",]\n",
    "    gas_prices_cols = [\"forecast_date\", \"lowest_price_per_mwh\", \"highest_price_per_mwh\"]\n",
    "    electricity_prices_cols = [\"forecast_date\", \"euros_per_mwh\"]\n",
    "    forecast_weather_cols = [\"latitude\",\"longitude\",\"hours_ahead\",\"temperature\",\"dewpoint\",\"cloudcover_high\",\"cloudcover_low\",\"cloudcover_mid\",\"cloudcover_total\",\"10_metre_u_wind_component\",\"10_metre_v_wind_component\",\"forecast_datetime\",\"direct_solar_radiation\",\"surface_solar_radiation_downwards\",\"snowfall\",\"total_precipitation\",]\n",
    "    historical_weather_cols = [\"datetime\",\"temperature\",\"dewpoint\",\"rain\",\"snowfall\",\"surface_pressure\",\"cloudcover_total\",\"cloudcover_low\",\"cloudcover_mid\",\"cloudcover_high\",\"windspeed_10m\",\"winddirection_10m\",\"shortwave_radiation\",\"direct_solar_radiation\",\"diffuse_radiation\",\"latitude\",\"longitude\",]\n",
    "    location_cols = [\"longitude\", \"latitude\", \"county\"]\n",
    "    target_cols = [\"target\",\"county\",\"is_business\",\"product_type\",\"is_consumption\",\"datetime\",]\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df_data = pl.read_csv(\n",
    "            os.path.join(self.root, \"train.csv\"),\n",
    "            columns=self.data_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_client = pl.read_csv(\n",
    "            os.path.join(self.root, \"client.csv\"),\n",
    "            columns=self.client_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_gas_prices = pl.read_csv(\n",
    "            os.path.join(self.root, \"gas_prices.csv\"),\n",
    "            columns=self.gas_prices_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_electricity_prices = pl.read_csv(\n",
    "            os.path.join(self.root, \"electricity_prices.csv\"),\n",
    "            columns=self.electricity_prices_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_forecast_weather = pl.read_csv(\n",
    "            os.path.join(self.root, \"forecast_weather.csv\"),\n",
    "            columns=self.forecast_weather_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_historical_weather = pl.read_csv(\n",
    "            os.path.join(self.root, \"historical_weather.csv\"),\n",
    "            columns=self.historical_weather_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_weather_station_to_county_mapping = pl.read_csv(\n",
    "            os.path.join(self.root, \"weather_station_to_county_mapping.csv\"),\n",
    "            columns=self.location_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_data = self.df_data.filter(\n",
    "            pl.col(\"datetime\") >= pd.to_datetime(\"2022-01-01\")\n",
    "        )\n",
    "        self.df_target = self.df_data.select(self.target_cols)\n",
    "\n",
    "        self.schema_data = self.df_data.schema\n",
    "        self.schema_client = self.df_client.schema\n",
    "        self.schema_gas_prices = self.df_gas_prices.schema\n",
    "        self.schema_electricity_prices = self.df_electricity_prices.schema\n",
    "        self.schema_forecast_weather = self.df_forecast_weather.schema\n",
    "        self.schema_historical_weather = self.df_historical_weather.schema\n",
    "        self.schema_target = self.df_target.schema\n",
    "\n",
    "        self.df_weather_station_to_county_mapping = (\n",
    "            self.df_weather_station_to_county_mapping.with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def update_with_new_data(\n",
    "        self,\n",
    "        df_new_client,\n",
    "        df_new_gas_prices,\n",
    "        df_new_electricity_prices,\n",
    "        df_new_forecast_weather,\n",
    "        df_new_historical_weather,\n",
    "        df_new_target,\n",
    "    ):\n",
    "        df_new_client = pl.from_pandas(\n",
    "            df_new_client[self.client_cols], schema_overrides=self.schema_client\n",
    "        )\n",
    "        df_new_gas_prices = pl.from_pandas(\n",
    "            df_new_gas_prices[self.gas_prices_cols],\n",
    "            schema_overrides=self.schema_gas_prices,\n",
    "        )\n",
    "        df_new_electricity_prices = pl.from_pandas(\n",
    "            df_new_electricity_prices[self.electricity_prices_cols],\n",
    "            schema_overrides=self.schema_electricity_prices,\n",
    "        )\n",
    "        df_new_forecast_weather = pl.from_pandas(\n",
    "            df_new_forecast_weather[self.forecast_weather_cols],\n",
    "            schema_overrides=self.schema_forecast_weather,\n",
    "        )\n",
    "        df_new_historical_weather = pl.from_pandas(\n",
    "            df_new_historical_weather[self.historical_weather_cols],\n",
    "            schema_overrides=self.schema_historical_weather,\n",
    "        )\n",
    "        df_new_target = pl.from_pandas(\n",
    "            df_new_target[self.target_cols], schema_overrides=self.schema_target\n",
    "        )\n",
    "\n",
    "        self.df_client = pl.concat([self.df_client, df_new_client]).unique(\n",
    "            [\"date\", \"county\", \"is_business\", \"product_type\"]\n",
    "        )\n",
    "        self.df_gas_prices = pl.concat([self.df_gas_prices, df_new_gas_prices]).unique(\n",
    "            [\"forecast_date\"]\n",
    "        )\n",
    "        self.df_electricity_prices = pl.concat(\n",
    "            [self.df_electricity_prices, df_new_electricity_prices]\n",
    "        ).unique([\"forecast_date\"])\n",
    "        self.df_forecast_weather = pl.concat(\n",
    "            [self.df_forecast_weather, df_new_forecast_weather]\n",
    "        ).unique([\"forecast_datetime\", \"latitude\", \"longitude\", \"hours_ahead\"])\n",
    "        self.df_historical_weather = pl.concat(\n",
    "            [self.df_historical_weather, df_new_historical_weather]\n",
    "        ).unique([\"datetime\", \"latitude\", \"longitude\"])\n",
    "        self.df_target = pl.concat([self.df_target, df_new_target]).unique(\n",
    "            [\"datetime\", \"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n",
    "        )\n",
    "\n",
    "    def preprocess_test(self, df_test):\n",
    "        df_test = df_test.rename(columns={\"prediction_datetime\": \"datetime\"})\n",
    "        df_test = pl.from_pandas(\n",
    "            df_test[self.data_cols[1:]], schema_overrides=self.schema_data\n",
    "        )\n",
    "        return df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87501628",
   "metadata": {
    "papermill": {
     "duration": 0.006849,
     "end_time": "2024-01-06T07:29:22.519342",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.512493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### FeaturesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d787217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:29:22.536317Z",
     "iopub.status.busy": "2024-01-06T07:29:22.535834Z",
     "iopub.status.idle": "2024-01-06T07:29:22.584538Z",
     "shell.execute_reply": "2024-01-06T07:29:22.583403Z"
    },
    "papermill": {
     "duration": 0.060895,
     "end_time": "2024-01-06T07:29:22.587302",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.526407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeaturesGenerator:\n",
    "    def __init__(self, data_storage):\n",
    "        self.data_storage = data_storage\n",
    "\n",
    "    def _add_general_features(self, df_features):\n",
    "        df_features = (\n",
    "            df_features.with_columns(\n",
    "                pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n",
    "                pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "                pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
    "                pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
    "                pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "                pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.concat_str(\n",
    "                    \"county\",\n",
    "                    \"is_business\",\n",
    "                    \"product_type\",\n",
    "                    \"is_consumption\",\n",
    "                    separator=\"_\",\n",
    "                ).alias(\"segment\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n",
    "                (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n",
    "                (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n",
    "                (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n",
    "            )\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _add_client_features(self, df_features):\n",
    "        df_client = self.data_storage.df_client\n",
    "\n",
    "        df_features = df_features.join(\n",
    "            df_client.with_columns(\n",
    "                (pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)\n",
    "            ),\n",
    "            on=[\"county\", \"is_business\", \"product_type\", \"date\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _add_forecast_weather_features(self, df_features):\n",
    "        df_forecast_weather = self.data_storage.df_forecast_weather\n",
    "        df_weather_station_to_county_mapping = (\n",
    "            self.data_storage.df_weather_station_to_county_mapping\n",
    "        )\n",
    "\n",
    "        df_forecast_weather = (\n",
    "            df_forecast_weather.rename({\"forecast_datetime\": \"datetime\"})\n",
    "            .filter((pl.col(\"hours_ahead\") >= 22) & pl.col(\"hours_ahead\") <= 45)\n",
    "            .drop(\"hours_ahead\")\n",
    "            .with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "            .join(\n",
    "                df_weather_station_to_county_mapping,\n",
    "                how=\"left\",\n",
    "                on=[\"longitude\", \"latitude\"],\n",
    "            )\n",
    "            .drop(\"longitude\", \"latitude\")\n",
    "        )\n",
    "\n",
    "        df_forecast_weather_date = (\n",
    "            df_forecast_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "        )\n",
    "\n",
    "        df_forecast_weather_local = (\n",
    "            df_forecast_weather.filter(pl.col(\"county\").is_not_null())\n",
    "            .group_by(\"county\", \"datetime\")\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        for hours_lag in [0, 7 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_forecast_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_forecast_{hours_lag}h\",\n",
    "            )\n",
    "            df_features = df_features.join(\n",
    "                df_forecast_weather_local.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=[\"county\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_forecast_local_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _add_historical_weather_features(self, df_features):\n",
    "        df_historical_weather = self.data_storage.df_historical_weather\n",
    "        df_weather_station_to_county_mapping = (\n",
    "            self.data_storage.df_weather_station_to_county_mapping\n",
    "        )\n",
    "\n",
    "        df_historical_weather = (\n",
    "            df_historical_weather.with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "            .join(\n",
    "                df_weather_station_to_county_mapping,\n",
    "                how=\"left\",\n",
    "                on=[\"longitude\", \"latitude\"],\n",
    "            )\n",
    "            .drop(\"longitude\", \"latitude\")\n",
    "        )\n",
    "\n",
    "        df_historical_weather_date = (\n",
    "            df_historical_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "        )\n",
    "\n",
    "        df_historical_weather_local = (\n",
    "            df_historical_weather.filter(pl.col(\"county\").is_not_null())\n",
    "            .group_by(\"county\", \"datetime\")\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        for hours_lag in [2 * 24, 7 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_{hours_lag}h\",\n",
    "            )\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_local.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=[\"county\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_local_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        for hours_lag in [1 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag),\n",
    "                    pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "                )\n",
    "                .filter(pl.col(\"hour\") <= 10)\n",
    "                .drop(\"hour\"),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _add_target_features(self, df_features):\n",
    "        df_target = self.data_storage.df_target\n",
    "\n",
    "        df_target_all_type_sum = (\n",
    "            df_target.group_by([\"datetime\", \"county\", \"is_business\", \"is_consumption\"])\n",
    "            .sum()\n",
    "            .drop(\"product_type\")\n",
    "        )\n",
    "\n",
    "        df_target_all_county_type_sum = (\n",
    "            df_target.group_by([\"datetime\", \"is_business\", \"is_consumption\"])\n",
    "            .sum()\n",
    "            .drop(\"product_type\", \"county\")\n",
    "        )\n",
    "\n",
    "        for hours_lag in [\n",
    "            2 * 24,\n",
    "            3 * 24,\n",
    "            4 * 24,\n",
    "            5 * 24,\n",
    "            6 * 24,\n",
    "            7 * 24,\n",
    "            8 * 24,\n",
    "            9 * 24,\n",
    "            10 * 24,\n",
    "            11 * 24,\n",
    "            12 * 24,\n",
    "            13 * 24,\n",
    "            14 * 24,\n",
    "        ]:\n",
    "            df_features = df_features.join(\n",
    "                df_target.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_{hours_lag}h\"}),\n",
    "                on=[\"county\",\"is_business\",\"product_type\",\"is_consumption\",\"datetime\",],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "        for hours_lag in [2 * 24, 3 * 24, 7 * 24, 14 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_target_all_type_sum.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_all_type_sum_{hours_lag}h\"}),\n",
    "                on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "            df_features = df_features.join(\n",
    "                df_target_all_county_type_sum.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_all_county_type_sum_{hours_lag}h\"}),\n",
    "                on=[\"is_business\", \"is_consumption\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_all_county_type_sum_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        cols_for_stats = [\n",
    "            f\"target_{hours_lag}h\" for hours_lag in [2 * 24, 3 * 24, 4 * 24, 5 * 24]\n",
    "        ]\n",
    "        df_features = df_features.with_columns(\n",
    "            df_features.select(cols_for_stats).mean(axis=1).alias(f\"target_mean\"),\n",
    "            df_features.select(cols_for_stats)\n",
    "            .transpose()\n",
    "            .std()\n",
    "            .transpose()\n",
    "            .to_series()\n",
    "            .alias(f\"target_std\"),\n",
    "        )\n",
    "\n",
    "        for target_prefix, lag_nominator, lag_denominator in [\n",
    "            (\"target\", 24 * 7, 24 * 14),\n",
    "            (\"target\", 24 * 2, 24 * 9),\n",
    "            (\"target\", 24 * 3, 24 * 10),\n",
    "            (\"target\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_type_sum\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_type_sum\", 24 * 7, 24 * 14),\n",
    "            (\"target_all_county_type_sum\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_county_type_sum\", 24 * 7, 24 * 14),\n",
    "        ]:\n",
    "            df_features = df_features.with_columns(\n",
    "                (\n",
    "                    pl.col(f\"{target_prefix}_{lag_nominator}h\")\n",
    "                    / (pl.col(f\"{target_prefix}_{lag_denominator}h\") + 1e-3)\n",
    "                ).alias(f\"{target_prefix}_ratio_{lag_nominator}_{lag_denominator}\")\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _reduce_memory_usage(self, df_features):\n",
    "        df_features = df_features.with_columns(pl.col(pl.Float64).cast(pl.Float32))\n",
    "        return df_features\n",
    "\n",
    "    def _drop_columns(self, df_features):\n",
    "        df_features = df_features.drop(\n",
    "            \"date\", \"datetime\", \"hour\", \"dayofyear\"\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _to_pandas(self, df_features, y):\n",
    "        cat_cols = [\"county\",\"is_business\",\"product_type\",\"is_consumption\",\"segment\",\n",
    "        ]\n",
    "\n",
    "        if y is not None:\n",
    "            df_features = pd.concat([df_features.to_pandas(), y.to_pandas()], axis=1)\n",
    "        else:\n",
    "            df_features = df_features.to_pandas()\n",
    "\n",
    "        df_features = df_features.set_index(\"row_id\")\n",
    "        df_features[cat_cols] = df_features[cat_cols].astype(\"category\")\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def generate_features(self, df_prediction_items):\n",
    "        if \"target\" in df_prediction_items.columns:\n",
    "            df_prediction_items, y = (\n",
    "                df_prediction_items.drop(\"target\"),\n",
    "                df_prediction_items.select(\"target\"),\n",
    "            )\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        df_features = df_prediction_items.with_columns(\n",
    "            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n",
    "        )\n",
    "\n",
    "        for add_features in [\n",
    "            self._add_general_features,\n",
    "            self._add_client_features,\n",
    "            self._add_forecast_weather_features,\n",
    "            self._add_historical_weather_features,\n",
    "            self._add_target_features,\n",
    "            self._reduce_memory_usage,\n",
    "            self._drop_columns,\n",
    "        ]:\n",
    "            df_features = add_features(df_features)\n",
    "\n",
    "        df_features = self._to_pandas(df_features, y)\n",
    "\n",
    "        return df_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e835e88",
   "metadata": {
    "papermill": {
     "duration": 0.006841,
     "end_time": "2024-01-06T07:29:22.601408",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.594567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0435d656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:29:22.618314Z",
     "iopub.status.busy": "2024-01-06T07:29:22.617213Z",
     "iopub.status.idle": "2024-01-06T07:29:22.630194Z",
     "shell.execute_reply": "2024-01-06T07:29:22.629049Z"
    },
    "papermill": {
     "duration": 0.023823,
     "end_time": "2024-01-06T07:29:22.632679",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.608856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.model_parameters = {\"n_estimators\": 2000,\"objective\": \"regression_l1\",\"learning_rate\": 0.05,\"colsample_bytree\": 0.89,\"colsample_bynode\": 0.596,\"lambda_l1\": 3.4895,\"lambda_l2\": 1.489,\"max_depth\": 15,\"num_leaves\": 490,\"min_data_in_leaf\": 48,'max_bin':840}\n",
    "\n",
    "        self.model_consumption = VotingRegressor(\n",
    "            [\n",
    "                (\n",
    "                    f\"consumption_lgb_{i}\",\n",
    "                    lgb.LGBMRegressor(**self.model_parameters, random_state=i),\n",
    "                )\n",
    "                for i in range(8)\n",
    "            ]\n",
    "        )\n",
    "        self.model_production = VotingRegressor(\n",
    "            [\n",
    "                (\n",
    "                    f\"production_lgb_{i}\",\n",
    "                    lgb.LGBMRegressor(**self.model_parameters, random_state=i),\n",
    "                )\n",
    "                for i in range(8)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def fit(self, df_train_features):\n",
    "        mask = df_train_features[\"is_consumption\"] == 1\n",
    "        self.model_consumption.fit(\n",
    "            X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "            y=df_train_features[mask][\"target\"]\n",
    "        )\n",
    "\n",
    "        mask = df_train_features[\"is_consumption\"] == 0\n",
    "        self.model_production.fit(\n",
    "            X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "            y=df_train_features[mask][\"target\"]\n",
    "        )\n",
    "\n",
    "    def predict(self, df_features):\n",
    "        predictions = np.zeros(len(df_features))\n",
    "\n",
    "        mask = df_features[\"is_consumption\"] == 1\n",
    "        predictions[mask.values] = self.model_consumption.predict(\n",
    "            df_features[mask]\n",
    "        ).clip(0)\n",
    "\n",
    "        mask = df_features[\"is_consumption\"] == 0\n",
    "        predictions[mask.values] = self.model_production.predict(\n",
    "            df_features[mask]\n",
    "        ).clip(0)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc48cde",
   "metadata": {
    "papermill": {
     "duration": 0.006553,
     "end_time": "2024-01-06T07:29:22.646240",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.639687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20c4d67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:29:22.661873Z",
     "iopub.status.busy": "2024-01-06T07:29:22.661455Z",
     "iopub.status.idle": "2024-01-06T07:29:28.527179Z",
     "shell.execute_reply": "2024-01-06T07:29:28.526333Z"
    },
    "papermill": {
     "duration": 5.876707,
     "end_time": "2024-01-06T07:29:28.529890",
     "exception": false,
     "start_time": "2024-01-06T07:29:22.653183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_storage = DataStorage()\n",
    "features_generator = FeaturesGenerator(data_storage=data_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd912335",
   "metadata": {
    "papermill": {
     "duration": 0.006597,
     "end_time": "2024-01-06T07:29:28.543862",
     "exception": false,
     "start_time": "2024-01-06T07:29:28.537265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c4f9521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:29:28.559684Z",
     "iopub.status.busy": "2024-01-06T07:29:28.559145Z",
     "iopub.status.idle": "2024-01-06T07:29:48.515966Z",
     "shell.execute_reply": "2024-01-06T07:29:48.514985Z"
    },
    "papermill": {
     "duration": 19.968373,
     "end_time": "2024-01-06T07:29:48.519077",
     "exception": false,
     "start_time": "2024-01-06T07:29:28.550704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_features = features_generator.generate_features(data_storage.df_data)\n",
    "df_train_features = df_train_features[df_train_features['target'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace0cdf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:29:48.536218Z",
     "iopub.status.busy": "2024-01-06T07:29:48.535574Z",
     "iopub.status.idle": "2024-01-06T07:30:52.635677Z",
     "shell.execute_reply": "2024-01-06T07:30:52.634451Z"
    },
    "papermill": {
     "duration": 64.113964,
     "end_time": "2024-01-06T07:30:52.640568",
     "exception": false,
     "start_time": "2024-01-06T07:29:48.526604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import holidays\n",
    "import datetime\n",
    "\n",
    "estonian_holidays = holidays.country_holidays('EE', years=range(2021, 2026))\n",
    "estonian_holidays = list(estonian_holidays.keys())\n",
    "\n",
    "def add_holidays_as_binary_features(df):\n",
    "    df['country_holiday'] = df.apply(lambda row: (datetime.date(row['year'], row['month'], row['day']) in estonian_holidays) * 1, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train_features = add_holidays_as_binary_features(df_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c3433",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bed85a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.489, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.489\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4895, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4895\n"
     ]
    }
   ],
   "source": [
    "training_model = Model()\n",
    "training_model.fit(df_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f8fcb7",
   "metadata": {
    "papermill": {
     "duration": 0.006426,
     "end_time": "2024-01-06T07:30:52.657021",
     "exception": false,
     "start_time": "2024-01-06T07:30:52.650595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957e47a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:30:52.672084Z",
     "iopub.status.busy": "2024-01-06T07:30:52.671555Z",
     "iopub.status.idle": "2024-01-06T07:30:52.676812Z",
     "shell.execute_reply": "2024-01-06T07:30:52.675697Z"
    },
    "papermill": {
     "duration": 0.015523,
     "end_time": "2024-01-06T07:30:52.679149",
     "exception": false,
     "start_time": "2024-01-06T07:30:52.663626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac1fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:30:52.695043Z",
     "iopub.status.busy": "2024-01-06T07:30:52.694368Z",
     "iopub.status.idle": "2024-01-06T07:31:35.719733Z",
     "shell.execute_reply": "2024-01-06T07:31:35.718391Z"
    },
    "papermill": {
     "duration": 43.036678,
     "end_time": "2024-01-06T07:31:35.722675",
     "exception": false,
     "start_time": "2024-01-06T07:30:52.685997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=Model()\n",
    "model.model_consumption= load('/kaggle/input/enefit-trained-model/voting_regressor_consumption_model.joblib')\n",
    "model.model_production= load('/kaggle/input/enefit-trained-model/voting_regressor_production_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42cd229",
   "metadata": {
    "papermill": {
     "duration": 0.006509,
     "end_time": "2024-01-06T07:31:35.736328",
     "exception": false,
     "start_time": "2024-01-06T07:31:35.729819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08112eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:31:35.752433Z",
     "iopub.status.busy": "2024-01-06T07:31:35.752004Z",
     "iopub.status.idle": "2024-01-06T07:31:35.772817Z",
     "shell.execute_reply": "2024-01-06T07:31:35.771865Z"
    },
    "papermill": {
     "duration": 0.032075,
     "end_time": "2024-01-06T07:31:35.775443",
     "exception": false,
     "start_time": "2024-01-06T07:31:35.743368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import enefit\n",
    "\n",
    "env = enefit.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314a4ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T07:31:35.791028Z",
     "iopub.status.busy": "2024-01-06T07:31:35.790648Z",
     "iopub.status.idle": "2024-01-06T07:32:44.053946Z",
     "shell.execute_reply": "2024-01-06T07:32:44.052752Z"
    },
    "papermill": {
     "duration": 68.274733,
     "end_time": "2024-01-06T07:32:44.057024",
     "exception": false,
     "start_time": "2024-01-06T07:31:35.782291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "for (df_test, df_new_target, df_new_client, df_new_historical_weather,df_new_forecast_weather, df_new_electricity_prices, df_new_gas_prices, df_sample_prediction) in iter_test:\n",
    "\n",
    "    data_storage.update_with_new_data(\n",
    "        df_new_client=df_new_client,\n",
    "        df_new_gas_prices=df_new_gas_prices,\n",
    "        df_new_electricity_prices=df_new_electricity_prices,\n",
    "        df_new_forecast_weather=df_new_forecast_weather,\n",
    "        df_new_historical_weather=df_new_historical_weather,\n",
    "        df_new_target=df_new_target\n",
    "    )\n",
    "    df_test = data_storage.preprocess_test(df_test)\n",
    "    \n",
    "    df_test_features = features_generator.generate_features(df_test)\n",
    "    df_test_features = add_holidays_as_binary_features(df_test_features)\n",
    "    df_sample_prediction[\"target\"] = model.predict(df_test_features)\n",
    "    \n",
    "    env.predict(df_sample_prediction)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7292407,
     "sourceId": 57236,
     "sourceType": "competition"
    },
    {
     "datasetId": 4266997,
     "sourceId": 7348254,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 210.430828,
   "end_time": "2024-01-06T07:32:45.290571",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-06T07:29:14.859743",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
